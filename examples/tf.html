<!DOCTYPE html>
<html>
<head>
  <title>CartPole RL</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
  <style>
    canvas { border: 1px solid black; }
    #info { margin-top: 10px; }
  </style>
</head>
<body>
  <canvas id="cartpole" width="600" height="400"></canvas>
  <div id="info">Episode: 0 | Score: 0</div>
  <button id="start-training">Start Training</button>
  <button id="pause-training">Pause Training</button>
  <button id="test">Test Agent</button>
  <script type="module">

    class CartPole {
      constructor() {
        this.gravity = 9.8;
        this.massCart = 1.0;
        this.massPole = 0.1;
        this.length = 0.5;
        this.forceMag = 10.0;
        this.tau = 0.02;
        this.reset();
      }

      reset = () =>{
        this.state = [0, 0, 0, 0]; 
        this.steps = 0;
      }

      step = (action) => {
        let [x, x_dot, theta, theta_dot] = this.state;
        const force = action === 1 ? this.forceMag : -this.forceMag;
        const cosTheta = Math.cos(theta);
        const sinTheta = Math.sin(theta);

        const temp = (force + this.massPole * this.length * theta_dot ** 2 * sinTheta) / (this.massCart + this.massPole);
        const thetaAcc = (this.gravity * sinTheta - cosTheta * temp) / (this.length * (4 / 3 - this.massPole * cosTheta ** 2 / (this.massCart + this.massPole)));
        const xAcc = temp - this.massPole * this.length * thetaAcc * cosTheta / (this.massCart + this.massPole);

        x += this.tau * x_dot;
        x_dot += this.tau * xAcc;
        theta += this.tau * theta_dot;
        theta_dot += this.tau * thetaAcc;

        this.state = [x, x_dot, theta, theta_dot];
        this.steps++;

        const done = x < -2.4 || x > 2.4 || theta < -0.209 || theta > 0.209;
        const reward = done ? -100 : 1;

        return { state: this.state, reward, done };
      }
    }

    class DQNAgent {
      gamma = 0.95;
      epsilon = 1.0;
      epsilonMin = 0.01;
      epsilonDecay = 0.995;
      memory = [];
      memorySize = 2000;
      batchSize = 32;
      learningRate = 0.001
      constructor(){
        const model = tf.sequential();
        model.add(tf.layers.dense({ units: 24, activation: 'relu', inputShape: [4] }));
        model.add(tf.layers.dense({ units: 24, activation: 'relu' }));
        model.add(tf.layers.dense({ units: 2, activation: 'linear' }));
        model.compile({
          optimizer: tf.train.adam(this.learningRate),
          loss: 'meanSquaredError'
        });
        this.model = model 
      }

      act = async (state) => {
        if (Math.random() < this.epsilon) return Math.floor(Math.random() * 2);

        const stateTensor = tf.tensor2d([state], [1, 4]);
        const qs = this.model.predict(stateTensor);
        const action = qs.argMax(1).dataSync()[0];
        stateTensor.dispose();
        qs.dispose();
        return action;
      }

      replay = async (state, action, reward, nextState, done) => {
        this.memory.push([state, action, reward, nextState, done]);
        if (this.memory.length > this.memorySize) this.memory.shift();

        if (this.memory.length < this.batchSize) return;

        const batch = this.memory.slice(-this.batchSize);
        const states = batch.map(([s]) => s);
        const nextStates = batch.map(([, , , ns]) => ns);
        const rewards = batch.map(([, , r]) => r);
        const actions = batch.map(([, a]) => a);
        const dones = batch.map(([, , , , d]) => d);

        const stateTensor = tf.tensor2d(states, [this.batchSize, 4]);
        const nextStateTensor = tf.tensor2d(nextStates, [this.batchSize, 4]);

        const qValues = this.model.predict(stateTensor);
        const nextQValues = this.model.predict(nextStateTensor);

        const qUpdates = qValues.dataSync().slice();
        console.log(qUpdates)
        const nextQMax = nextQValues.max(1).dataSync();

        for (let i = 0; i < this.batchSize; i++) {
          const target = dones[i] ? rewards[i] : rewards[i] + this.gamma * nextQMax[i];
          qUpdates[i * 2 + actions[i]] = target;
        }

        await this.model.fit(stateTensor, tf.tensor2d(qUpdates, [this.batchSize, 2]), { epochs: 1, verbose: 0 });

        stateTensor.dispose();
        nextStateTensor.dispose();
        qValues.dispose();
        nextQValues.dispose();

        if (this.epsilon > this.epsilonMin) this.epsilon *= this.epsilonDecay;
      }
    }

    // Rendering and Game Loop
    const canvas = document.getElementById('cartpole');
    const ctx = canvas.getContext('2d');
    const env = new CartPole();
    const agent = new DQNAgent();
    let isTraining = false;
    let episode = 0;
    let totalReward = 0;

    const render = () => {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      const [x, , theta] = env.state;

      // Draw track
      ctx.beginPath();
      ctx.moveTo(0, 300);
      ctx.lineTo(600, 300);
      ctx.stroke();

      // Draw cart
      const cartX = x * 100 + 300;
      ctx.fillStyle = 'blue';
      ctx.fillRect(cartX - 20, 280, 40, 20);

      // Draw pole
      const poleX = cartX;
      const poleY = 280;
      const poleLength = 100;
      ctx.beginPath();
      ctx.moveTo(poleX, poleY);
      ctx.lineTo(poleX + poleLength * Math.sin(theta), poleY - poleLength * Math.cos(theta));
      ctx.strokeStyle = 'red';
      ctx.lineWidth = 5;
      ctx.stroke();
    }

    const trainStep = async () => {
      if (!isTraining) return;

      let state = env.state;
      const action = await agent.act(state);
      const { state: nextState, reward, done } = env.step(action);
      await agent.replay(state, action, reward, nextState, done);
      totalReward += reward;

      render();
      document.getElementById('info').innerText = `Episode: ${episode} | Score: ${totalReward}`;

      if (done) {
        episode++;
        totalReward = 0;
        env.reset();
      }

      if (isTraining) requestAnimationFrame(trainStep);
    }

    const startTraining = () => {
      isTraining = true;
      trainStep();
    }

    const pauseTraining = () => {
      isTraining = false;
    }

    async function testAgent() {
      isTraining = false;
      env.reset();
      totalReward = 0;
      agent.epsilon = 0; 
      while (true) {
        const state = env.state;
        const action = await agent.act(state);
        const { reward, done } = env.step(action);
        totalReward += reward;
        render();
        document.getElementById('info').innerText = `Test Score: ${totalReward}`;
        if (done) break;
        // await new Promise(resolve => setTimeout(resolve, 50)); // Slow down for visibility
      }
      agent.epsilon = Math.max(agent.epsilonMin, agent.epsilon); // Restore exploration
    }

    document.querySelector("#start-training").addEventListener("click", startTraining)
    document.querySelector("#pause-training").addEventListener("click", pauseTraining)
    document.querySelector("#test").addEventListener("click", testAgent)

    render();
  </script>
</body>
</html>